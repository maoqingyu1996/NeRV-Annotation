{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 定义一个模型对象\n",
    "model = LeNet().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', Parameter containing:\n",
      "tensor([[[[-0.2208, -0.1358,  0.0358],\n",
      "          [ 0.1709, -0.1481,  0.0807],\n",
      "          [ 0.0473, -0.2835, -0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3225,  0.3260,  0.1842],\n",
      "          [-0.1492, -0.3042, -0.1112],\n",
      "          [-0.2454, -0.2889, -0.3324]]],\n",
      "\n",
      "\n",
      "        [[[-0.1071,  0.1120,  0.1521],\n",
      "          [ 0.0496,  0.3321, -0.0295],\n",
      "          [-0.3143, -0.0115, -0.1824]]],\n",
      "\n",
      "\n",
      "        [[[-0.0187,  0.1187,  0.2150],\n",
      "          [-0.0522, -0.1837,  0.1312],\n",
      "          [-0.1356, -0.0675,  0.2507]]],\n",
      "\n",
      "\n",
      "        [[[-0.3119, -0.1307,  0.0213],\n",
      "          [ 0.0547,  0.1024,  0.2038],\n",
      "          [-0.1779, -0.2047, -0.2900]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1869, -0.1298,  0.3185],\n",
      "          [ 0.2846, -0.3239, -0.1929],\n",
      "          [ 0.2458, -0.0701,  0.0273]]]], device='cuda:0', requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([ 0.2520,  0.2080, -0.1745,  0.0363, -0.0401,  0.2278], device='cuda:0',\n",
      "       requires_grad=True))]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 模型的第一层 六个3*3的卷积核\n",
    "module = model.conv1\n",
    "# 这里是函数\n",
    "print(list(module.named_parameters())) # 打印了权重weight和偏差bias\n",
    "print(list(module.named_buffers())) # 目前打印为空\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bias', Parameter containing:\n",
      "tensor([ 0.2520,  0.2080, -0.1745,  0.0363, -0.0401,  0.2278], device='cuda:0',\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[-0.2208, -0.1358,  0.0358],\n",
      "          [ 0.1709, -0.1481,  0.0807],\n",
      "          [ 0.0473, -0.2835, -0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3225,  0.3260,  0.1842],\n",
      "          [-0.1492, -0.3042, -0.1112],\n",
      "          [-0.2454, -0.2889, -0.3324]]],\n",
      "\n",
      "\n",
      "        [[[-0.1071,  0.1120,  0.1521],\n",
      "          [ 0.0496,  0.3321, -0.0295],\n",
      "          [-0.3143, -0.0115, -0.1824]]],\n",
      "\n",
      "\n",
      "        [[[-0.0187,  0.1187,  0.2150],\n",
      "          [-0.0522, -0.1837,  0.1312],\n",
      "          [-0.1356, -0.0675,  0.2507]]],\n",
      "\n",
      "\n",
      "        [[[-0.3119, -0.1307,  0.0213],\n",
      "          [ 0.0547,  0.1024,  0.2038],\n",
      "          [-0.1779, -0.2047, -0.2900]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1869, -0.1298,  0.3185],\n",
      "          [ 0.2846, -0.3239, -0.1929],\n",
      "          [ 0.2458, -0.0701,  0.0273]]]], device='cuda:0', requires_grad=True))]\n",
      "[('weight_mask', tensor([[[[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [0., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 1.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [0., 1., 1.],\n",
      "          [0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 0., 1.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1.],\n",
      "          [1., 1., 1.],\n",
      "          [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]]]], device='cuda:0'))]\n",
      "tensor([[[[-0.2208, -0.0000,  0.0000],\n",
      "          [ 0.1709, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.2835, -0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.1842],\n",
      "          [-0.1492, -0.3042, -0.0000],\n",
      "          [-0.2454, -0.2889, -0.3324]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.1120,  0.0000],\n",
      "          [ 0.0000,  0.3321, -0.0295],\n",
      "          [-0.0000, -0.0000, -0.1824]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.1187,  0.0000],\n",
      "          [-0.0522, -0.0000,  0.1312],\n",
      "          [-0.0000, -0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.1307,  0.0213],\n",
      "          [ 0.0547,  0.1024,  0.2038],\n",
      "          [-0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.1298,  0.0000],\n",
      "          [ 0.2846, -0.3239, -0.0000],\n",
      "          [ 0.2458, -0.0701,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "OrderedDict([(1, <torch.nn.utils.prune.PruningContainer object at 0x7f0654782a60>)])\n"
     ]
    }
   ],
   "source": [
    "prune.random_unstructured(module, name=\"weight\", amount=0.3) # 裁剪单个module，这里裁剪了个卷积层\n",
    "\n",
    "print(list(module.named_parameters())) # 参数与原来是相同的，但是不是weight，而是weight_orig\n",
    "\n",
    "print(list(module.named_buffers())) # 产生一个weight_mask的掩码，产生一个weight的属性\n",
    "\n",
    "print(module.weight) # 这里是属性\n",
    "\n",
    "print(module._forward_pre_hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<torch.nn.utils.prune.RandomUnstructured object at 0x7f06545835b0>, <torch.nn.utils.prune.RandomUnstructured object at 0x7f0654782eb0>, <torch.nn.utils.prune.LnStructured object at 0x7f0654782e80>, <torch.nn.utils.prune.LnStructured object at 0x7f0544f16580>]\n"
     ]
    }
   ],
   "source": [
    "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
    "\n",
    "for hook in module._forward_pre_hooks.values():\n",
    "    if hook._tensor_name == \"weight\":\n",
    "       break\n",
    "print(list(hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (1218652873.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [15], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    100\\. * float(torch.sum(model.conv1.weight == 0))\u001b[0m\n\u001b[0m                                                     \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (model.conv1, 'weight'),\n",
    "    (model.conv2, 'weight'),\n",
    "    (model.fc1, 'weight'),\n",
    "    (model.fc2, 'weight'),\n",
    "    (model.fc3, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Sparsity in conv1.weight: {:.2f}%\".format(\\\n",
    "        100\\. * float(torch.sum(model.conv1.weight == 0))\n",
    "        / float(model.conv1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "        100\\. * float(torch.sum(model.conv2.weight == 0))\n",
    "        / float(model.conv2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "        100\\. * float(torch.sum(model.fc1.weight == 0))\n",
    "        / float(model.fc1.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
    "        100\\. * float(torch.sum(model.fc2.weight == 0))\n",
    "        / float(model.fc2.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
    "        100\\. * float(torch.sum(model.fc3.weight == 0))\n",
    "        / float(model.fc3.weight.nelement())\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Global sparsity: {:.2f}%\".format(\n",
    "        100\\. * float(\n",
    "            torch.sum(model.conv1.weight == 0)\n",
    "            + torch.sum(model.conv2.weight == 0)\n",
    "            + torch.sum(model.fc1.weight == 0)\n",
    "            + torch.sum(model.fc2.weight == 0)\n",
    "            + torch.sum(model.fc3.weight == 0)\n",
    "        )\n",
    "        / float(\n",
    "            model.conv1.weight.nelement()\n",
    "            + model.conv2.weight.nelement()\n",
    "            + model.fc1.weight.nelement()\n",
    "            + model.fc2.weight.nelement()\n",
    "            + model.fc3.weight.nelement()\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('enerv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9629b341e57dc1e7f03436d476b39c5243e48e6aa96449615c1dad1d704bbe44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
